{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "latter-impact",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-transcript",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "funded-providence",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = \"assignment3_train\\\\train\"\n",
    "path_test = \"assignment3_test\\\\test\"\n",
    "itr = 500\n",
    "lam = 0.01\n",
    "theta = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "convenient-stylus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Word Count: 9186\n"
     ]
    }
   ],
   "source": [
    "sizett = 0\n",
    "size_spam = 0\n",
    "size_ham = 0\n",
    "x = os.listdir(path_train)\n",
    "spamwc={}\n",
    "hamwc = {}\n",
    "totalwc = {}\n",
    "for i in x:\n",
    "    y = os.listdir(path_train+\"\\\\\" + i)\n",
    "    if i==\"spam\":\n",
    "        for j in y:\n",
    "            sizett += 1\n",
    "            size_spam += 1\n",
    "            f = path_train+\"\\\\\"+ i + \"\\\\\" + j\n",
    "            file=open(f,\"r\", errors = 'ignore')\n",
    "            for word in file.read().split():\n",
    "                if word not in spamwc and word.isalpha():\n",
    "                    spamwc[word] = 1\n",
    "                    totalwc[word] = 1\n",
    "                elif word.isalpha():\n",
    "                    spamwc[word] += 1\n",
    "                    totalwc[word] += 1\n",
    "    else:\n",
    "        for j in y:\n",
    "            sizett += 1\n",
    "            size_ham += 1\n",
    "            f = path_train+\"\\\\\"+ i + \"\\\\\" + j\n",
    "            file=open(f,\"r\", errors = 'ignore')\n",
    "            for word in file.read().split():\n",
    "                if word not in hamwc and word.isalpha():\n",
    "                    hamwc[word] = 1\n",
    "                    totalwc[word] = 1\n",
    "                elif word.isalpha():\n",
    "                    hamwc[word] += 1\n",
    "                    totalwc[word] += 1\n",
    "print(\"Total Word Count:\",len(totalwc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-position",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "responsible-dream",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9219214600635702\n"
     ]
    }
   ],
   "source": [
    "totalw_s = sum(spamwc.values())\n",
    "totalw_h = sum(hamwc.values())\n",
    "novoc = len(totalwc)\n",
    "cs = 0\n",
    "ch = 0\n",
    "cst = 0\n",
    "cht = 0\n",
    "size_test = 0\n",
    "# Naive Bayes\n",
    "for i in x:\n",
    "    y = os.listdir(path_test+\"\\\\\"+ i)\n",
    "    for j in y:\n",
    "        test_sh = {}\n",
    "        size_test += 1\n",
    "        f = path_test+\"\\\\\"+ i + \"\\\\\" + j\n",
    "        file=open(f,\"r\", errors = 'ignore')\n",
    "        for word in file.read().split():\n",
    "            if word not in test_sh and word.isalpha():\n",
    "                test_sh[word] = 1\n",
    "            elif word.isalpha():\n",
    "                test_sh[word] += 1\n",
    "        prob_s = math.log(size_spam/sizett)\n",
    "        prob_h = math.log(size_ham/sizett)\n",
    "        for k in test_sh:\n",
    "            if spamwc.get(k) != None:\n",
    "                prob_s = prob_s + math.log((spamwc.get(k)+1)/((totalw_s)+(novoc)))\n",
    "            else:\n",
    "                prob_s = prob_s + math.log((1)/((totalw_s)+(novoc)))\n",
    "            if hamwc.get(k) != None:\n",
    "                prob_h = prob_h + math.log((hamwc.get(k)+1)/((totalw_h)+(novoc)))\n",
    "            else:\n",
    "                prob_h = prob_h + math.log((1)/((totalw_h)+(novoc)))\n",
    "\n",
    "            if prob_s > prob_h:\n",
    "                cs = cs + 1\n",
    "                if i==\"spam\":\n",
    "                    cst = cst + 1\n",
    "            elif prob_h > prob_s:\n",
    "                ch = ch + 1\n",
    "                if i==\"ham\":\n",
    "                    cht = cht + 1\n",
    "\n",
    "print(\"Accuracy\",(cst+cht)/(cs+ch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-paris",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "exact-brother",
   "metadata": {},
   "outputs": [],
   "source": [
    "ltotalwc = list(totalwc.keys())\n",
    "mat = np.zeros((sizett,len(ltotalwc)+1))\n",
    "ind = 0\n",
    "for i in x:\n",
    "    y = os.listdir(path_train+\"\\\\\"+ i)\n",
    "    for j in y:\n",
    "        logwc = {}\n",
    "        f = path_train+\"\\\\\"+ i + \"\\\\\" + j\n",
    "        file=open(f,\"r\", errors = 'ignore')\n",
    "        for word in file.read().split():\n",
    "            if word not in logwc and word.isalpha():\n",
    "                logwc[word] = 1\n",
    "            elif word.isalpha():\n",
    "                logwc[word] += 1\n",
    "        for k in logwc:\n",
    "            mat[ind][ltotalwc.index(k)] = logwc[k]\n",
    "        if i==\"spam\":\n",
    "            mat[ind][len(ltotalwc)] = 1\n",
    "        ind = ind + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "mediterranean-norwegian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob(w,x):\n",
    "    s = 0\n",
    "    for i in range(len(x)):\n",
    "        s = s + (w[i]*x[i])\n",
    "    try:\n",
    "        p = math.exp(w[0]+s)/(1 + math.exp(w[0]+s))\n",
    "    except:\n",
    "        p = 1\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "going-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_new = np.ones(len(totalwc)+1)\n",
    "w = np.ones(len(totalwc)+1)\n",
    "probab = np.ones(mat.shape[0])\n",
    "for k in range(itr):\n",
    "    w = w_new.copy()\n",
    "    w_new = np.ones(len(totalwc)+1)\n",
    "    for l in range(mat.shape[0]):\n",
    "        probab[l] = prob(w,mat[l])\n",
    "    for i in range(len(w)):\n",
    "        temp = 0\n",
    "        for j in range(mat.shape[0]):\n",
    "            temp = temp + mat[j][i]*((mat[j][mat.shape[1]-1])-probab[j])\n",
    "        w_new[i] = w[i]+ (lam * temp) - (lam*theta*w[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "trying-rehabilitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_test = np.zeros((size_test,len(ltotalwc)+1))\n",
    "ind = 0\n",
    "for i in x:\n",
    "    y = os.listdir(path_test+\"\\\\\"+ i)\n",
    "    for j in y:\n",
    "        logwc = {}\n",
    "        f = path_test+\"\\\\\"+ i + \"\\\\\" + j\n",
    "        file=open(f,\"r\", errors = 'ignore')\n",
    "        for word in file.read().split():\n",
    "            if word not in logwc and word.isalpha():\n",
    "                logwc[word] = 1\n",
    "            elif word.isalpha():\n",
    "                logwc[word] += 1\n",
    "        for k in logwc:\n",
    "            if k in ltotalwc:\n",
    "                mat_test[ind][ltotalwc.index(k)] = logwc[k]\n",
    "        if i==\"spam\":\n",
    "            mat_test[ind][len(ltotalwc)] = 1\n",
    "        ind = ind + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "periodic-plastic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8744769874476988\n"
     ]
    }
   ],
   "source": [
    "th = 0\n",
    "ts = 0\n",
    "tt = 0\n",
    "for i in range(mat_test.shape[0]):\n",
    "    s = 0\n",
    "    for j in range(mat_test.shape[1]-1):\n",
    "        s = s + (w_new[j]*mat_test[i][j])\n",
    "    s = s + w[0]\n",
    "    tt += 1\n",
    "    if mat_test[i][len(ltotalwc)]==1 and s>0:\n",
    "        ts += 1\n",
    "    elif mat_test[i][len(ltotalwc)]==0 and s<0:\n",
    "        th += 1\n",
    "print(\"Accuracy:\",(ts+th)/tt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-youth",
   "metadata": {},
   "source": [
    "## After Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "suited-money",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = [\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\",\n",
    "             \"any\", \"are\", \"aren't\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\",\n",
    "             \"between\", \"both\", \"but\", \"by\", \"can't\", \"cannot\", \"could\", \"couldn't\", \"did\", \"didn't\",\n",
    "             \"do\", \"does\", \"doesn't\", \"doing\", \"don't\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\",\n",
    "             \"further\", \"had\", \"hadn't\", \"has\", \"hasn't\", \"have\", \"haven't\", \"having\", \"he\", \"he'd\",\n",
    "             \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\",\n",
    "             \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"isn't\", \"it\", \"it's\", \"its\",\n",
    "             \"itself\", \"let's\", \"me\", \"more\", \"most\", \"mustn't\", \"my\", \"myself\", \"no\", \"nor\", \"not\", \"of\",\n",
    "             \"off\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\",\n",
    "             \"own\", \"same\", \"shan't\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"shouldn't\", \"so\", \"some\",\n",
    "             \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\",\n",
    "             \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\",\n",
    "             \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"wasn't\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\",\n",
    "             \"were\", \"weren't\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\",\n",
    "             \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"won't\", \"would\", \"wouldn't\", \"you\", \"you'd\", \"you'll\",\n",
    "             \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "tutorial-clarity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Word Count: 9068\n"
     ]
    }
   ],
   "source": [
    "x = os.listdir(path_train)\n",
    "spamwc={}\n",
    "hamwc = {}\n",
    "totalwc = {}\n",
    "for i in x:\n",
    "    y = os.listdir(path_train+\"\\\\\"+ i)\n",
    "    if i==\"spam\":\n",
    "        for j in y:\n",
    "            f = path_train+\"\\\\\"+ i + \"\\\\\" + j\n",
    "            file=open(f,\"r\", errors = 'ignore')\n",
    "            for word in file.read().split():\n",
    "                if word not in stopWords:\n",
    "                    if word not in spamwc and word.isalpha():\n",
    "                        spamwc[word] = 1\n",
    "                        totalwc[word] = 1\n",
    "                    elif word.isalpha():\n",
    "                        spamwc[word] += 1\n",
    "                        totalwc[word] += 1\n",
    "    else:\n",
    "        for j in y:\n",
    "            f = path_train+\"\\\\\"+ i + \"\\\\\" + j\n",
    "            file=open(f,\"r\", errors = 'ignore')\n",
    "            for word in file.read().split():\n",
    "                if word not in stopWords:\n",
    "                    if word not in hamwc and word.isalpha():\n",
    "                        hamwc[word] = 1\n",
    "                        totalwc[word] = 1\n",
    "                    elif word.isalpha():\n",
    "                        hamwc[word] += 1\n",
    "                        totalwc[word] += 1\n",
    "\n",
    "print(\"Total Word Count:\",len(totalwc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-sudan",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "visible-effects",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9231868643222761\n"
     ]
    }
   ],
   "source": [
    "totalw_s = sum(spamwc.values())\n",
    "totalw_h = sum(hamwc.values())\n",
    "novoc = len(totalwc)\n",
    "cs = 0\n",
    "ch = 0\n",
    "cst = 0\n",
    "cht = 0\n",
    "for i in x:\n",
    "    y = os.listdir(path_test+\"\\\\\"+ i)\n",
    "    for j in y:\n",
    "        test_sh = {}\n",
    "        f = path_test+\"\\\\\"+ i + \"\\\\\" + j\n",
    "        file=open(f,\"r\", errors = 'ignore')\n",
    "        for word in file.read().split():\n",
    "            if word not in stopWords:\n",
    "                if word not in test_sh and word.isalpha():\n",
    "                    test_sh[word] = 1\n",
    "                elif word.isalpha():\n",
    "                    test_sh[word] += 1\n",
    "        prob_s = math.log(size_spam/sizett)\n",
    "        prob_h = math.log(size_ham/sizett)\n",
    "        # print(prob_s, prob_h)\n",
    "        for k in test_sh:\n",
    "            if spamwc.get(k) != None:\n",
    "                prob_s = prob_s + math.log((spamwc.get(k)+1)/((totalw_s)+(novoc)))\n",
    "            else:\n",
    "                prob_s = prob_s + math.log((1)/((totalw_s)+(novoc)))\n",
    "            if hamwc.get(k) != None:\n",
    "                prob_h = prob_h + math.log((hamwc.get(k)+1)/((totalw_h)+(novoc)))\n",
    "            else:\n",
    "                prob_h = prob_h + math.log((1)/((totalw_h)+(novoc)))\n",
    "\n",
    "            if prob_s > prob_h:\n",
    "                cs = cs + 1\n",
    "                if i==\"spam\":\n",
    "                    cst = cst + 1\n",
    "            elif prob_h > prob_s:\n",
    "                ch = ch + 1\n",
    "                if i==\"ham\":\n",
    "                    cht = cht + 1\n",
    "\n",
    "print(\"Accuracy\",(cst+cht)/(cs+ch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-renaissance",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cleared-lotus",
   "metadata": {},
   "outputs": [],
   "source": [
    "ltotalwc = list(totalwc.keys())\n",
    "mat = np.zeros((sizett,len(ltotalwc)+1))\n",
    "ind = 0\n",
    "for i in x:\n",
    "    y = os.listdir(path_train+\"\\\\\"+ i)\n",
    "    for j in y:\n",
    "        logwc = {}\n",
    "        f = path_train+\"\\\\\"+ i + \"\\\\\" + j\n",
    "        file=open(f,\"r\", errors = 'ignore')\n",
    "        for word in file.read().split():\n",
    "            if word not in stopWords:\n",
    "                if word not in logwc and word.isalpha():\n",
    "                    logwc[word] = 1\n",
    "                elif word.isalpha():\n",
    "                    logwc[word] += 1\n",
    "        for k in logwc:\n",
    "            mat[ind][ltotalwc.index(k)] = logwc[k]\n",
    "        if i==\"spam\":\n",
    "            mat[ind][len(ltotalwc)] = 1\n",
    "        ind = ind + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "latter-combat",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_new = np.ones(len(totalwc)+1)\n",
    "w = np.ones(len(totalwc)+1)\n",
    "for k in range(itr):\n",
    "    w = w_new.copy()\n",
    "    w_new = np.ones(len(totalwc)+1)\n",
    "    for l in range(mat.shape[0]):\n",
    "        probab[l] = prob(w,mat[l])\n",
    "    for i in range(len(w)):\n",
    "        temp = 0\n",
    "        for j in range(mat.shape[0]):\n",
    "            temp = temp + mat[j][i]*((mat[j][mat.shape[1]-1])-probab[j])\n",
    "        w_new[i] = w[i]+ (lam * temp) - (lam*theta*w[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "caring-vehicle",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_test = np.zeros((size_test,len(ltotalwc)+1))\n",
    "ind = 0\n",
    "for i in x:\n",
    "    y = os.listdir(path_test+\"\\\\\"+ i)\n",
    "    for j in y:\n",
    "        logwc = {}\n",
    "        f = path_test+\"\\\\\"+ i + \"\\\\\" + j\n",
    "        file=open(f,\"r\", errors = 'ignore')\n",
    "        for word in file.read().split():\n",
    "            if word not in stopWords:\n",
    "                if word not in logwc and word.isalpha():\n",
    "                    logwc[word] = 1\n",
    "                elif word.isalpha():\n",
    "                    logwc[word] += 1\n",
    "        for k in logwc:\n",
    "            if k in ltotalwc:\n",
    "                mat_test[ind][ltotalwc.index(k)] = logwc[k]\n",
    "        if i==\"spam\":\n",
    "            mat_test[ind][len(ltotalwc)] = 1\n",
    "        ind = ind + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "finnish-computer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8640167364016736\n"
     ]
    }
   ],
   "source": [
    "th = 0\n",
    "ts = 0\n",
    "tt = 0\n",
    "for i in range(mat_test.shape[0]):\n",
    "    s = 0\n",
    "    for j in range(mat_test.shape[1]-1):\n",
    "        s = s + (w_new[j]*mat_test[i][j])\n",
    "    s = s + w[0]\n",
    "    tt += 1\n",
    "    if mat_test[i][len(ltotalwc)]==1 and s>0:\n",
    "        ts += 1\n",
    "    elif mat_test[i][len(ltotalwc)]==0 and s<0:\n",
    "        th += 1\n",
    "print(\"Accuracy:\",(ts+th)/tt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
